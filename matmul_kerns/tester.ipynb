{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b20748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fb935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mma_m, mma_n, mma_k = 16,8,16 \n",
    "\n",
    "#okay think about this, if we have acc_per_warp_m, acc_per_warp_n \n",
    "#then this (always mma tile granular) induces a acc_per_warp_m x K by K x acc_per_warp_n matmul. \n",
    "\n",
    "#this is actually a shared memory situation so it s actually a \n",
    "\n",
    "# acc_per_warp_m x BK by BK x acc_per_warp_n matmul. \n",
    "\n",
    "#indeed, once chooses a paramater BK_stages \n",
    "#so the done matmul by 1 warp is of shape (mma_m*acc_per_warp_m, mma_n*acc_per_warp_n, mma_k*BK)\n",
    "#done in stages\n",
    "\n",
    "#the matmul happens, for each loop its is (in tile granular, acc_per_warp_m, acc_per_warp_n, BK_stages)\n",
    "# \n",
    "\n",
    "acc_per_warp_m = 2\n",
    "acc_per_warp_n = 4\n",
    "BK_stages = 2 \n",
    "\n",
    "num_c_acc = acc_per_warp_m*acc_per_warp_n \n",
    "num_a_frags = acc_per_warp_m*BK_stages \n",
    "num_b_frags = acc_per_warp_n*BK_stages \n",
    "\n",
    "num_32_bit_regs = ((num_c_acc*4) + ((num_a_frags*2)+(num_b_frags)))*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2d686f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_32_bit_regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b798e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "shared As[2],Bs[2]\n",
    "\n",
    "bar empty[2] \n",
    "bar full[2] \n",
    "\n",
    "#prologue\n",
    "\n",
    "waste_token = (empty[0].arrive())\n",
    "waste_token = (empty[1].arrive())\n",
    "\n",
    "if (threadIdx.x == 0):\n",
    "\n",
    "  empty[0].wait(empty[0].arrive())\n",
    "  \n",
    "  TMA_fill(As[0], Bs[0], full[0] k_iter = 0)\n",
    "  waste_token = barrier_arrive_tx(full[0], As_bytes + Bs_bytes) \n",
    "  \n",
    "else: \n",
    "  waste_token = full[0].arrive()\n",
    "  \n",
    "  \n",
    "for bk in [0,bk_iters): \n",
    "  stage = (bk % 2)\n",
    "  next = (bk + 1) % 2 \n",
    "  \n",
    "  if (threadIdx == 0 and bk + 1 < bk_iters): \n",
    "    empty[next].wait(empty[next].arrive())\n",
    "    TMA_fill(As[next],Bs[next],full[next], k_iter = bk + 1)\n",
    "    waste_token = barrier_arrive_tx(full[next], AS_bytes + Bs_bytes)\n",
    "  else: \n",
    "    waste_token = full[next].arrive()\n",
    "  \n",
    "  \n",
    "  full[stage].wait(full[stage].arrive())    \n",
    "  COMPUTE(As[stage], Bs[stage]) \n",
    "  \n",
    "   waste_token = empty[stage].arrive()\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
